{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TiSTHbA25ZtB"
   },
   "source": [
    "# Accessing the ATLAS Open Data\n",
    "\n",
    "This notebook is based on the use of  ATLAS Open Data \n",
    "http://opendata.atlas.cern\n",
    "\n",
    "ATLAS Open Data provides open access to proton-proton collision data at the LHC. \n",
    "\n",
    "The ATLAS Collaboration makes avaliable approximately 1/10 of the data and the corresponding Monte Carlo samples for didactic purposes. \n",
    "\n",
    "The data are made available under the form of ROOT ntuples, the contents are discussed in the introduction to the hands-on exercise\n",
    "\n",
    "\n",
    "The purpose of this nootebook is to give an example of access to these ntuples based on the uproot package and to load the data onto a panda dataframe and to save them as csv files for further use \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dgRkVPu5ZtK"
   },
   "source": [
    "## Installation of packages not available by default on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjpPQFJHBHZO",
    "outputId": "bbfaa500-8482-4f73-d0a6-6a3ea80ffb27"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# update the pip package installer\n",
    "#%pip install --upgrade --user pip\n",
    "# install required packages\n",
    "#%pip install --upgrade --user uproot awkward vector numpy matplotlib\n",
    "\n",
    "#!pip install uproot\n",
    "#!pip install vector\n",
    "#!pip install awkward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrW2zmSv5ZtP"
   },
   "source": [
    "## Import packages used in the analysis\n",
    "\n",
    "We're going to be using a number of tools to help us:\n",
    "* uproot: lets us read .root files typically used in particle physics into data formats used in python\n",
    "* awkward: lets us store data as awkward arrays, a format that generalizes numpy to nested data with possibly variable length lists\n",
    "* vector: to allow vectorized 4-momentum calculations\n",
    "* numpy: provides numerical calculations such as histogramming\n",
    "* matplotlib: common tool for making plots, figures, images, visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0tezkWvi5ZtP"
   },
   "outputs": [],
   "source": [
    "import uproot # for reading .root files\n",
    "import awkward as ak # to represent nested data in columnar format\n",
    "import vector # for 4-momentum calculations\n",
    "import time # to measure time to analyse\n",
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8hU5HN-5ZtQ"
   },
   "source": [
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQfajNQQ5ZtR"
   },
   "source": [
    "<a id='fraction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1jsgyX25ZtR"
   },
   "source": [
    "## File path\n",
    "\n",
    "Files for processes including two leptons in the final state. We consider three files including the following simulated physics processes:\n",
    "\n",
    "* pp -> WW -> llvv\n",
    "* pp -> h -> WW -> llvv\n",
    "* pp -> tt -> WWbb -> bbllvv\n",
    "\n",
    "where \"l\" is an electron or a muon, \"v\" is a neutrino, escaping detection, and \"b\" is a jet produced from the hadronisation of a b-quark\n",
    "\n",
    "The files are accessed on the fly from the open data repository at CERN, you may want to download them locally if you want to run faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isamp=3\n",
    "fn1=\"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_363492.llvv.2lep.root\"\n",
    "norm1=0.02473775926465947 # WW normalisation\n",
    "filename='ww_atlas.csv.gz'\n",
    "if isamp==2:\n",
    "  fn1=\"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_345324.ggH125_WW2lep.2lep.root\"\n",
    "  norm1=2.652880224948454e-05 # HWW normalisation\n",
    "  filename='hww_atlas.csv.gz'\n",
    "if isamp==3:\n",
    "  fn1=\"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/2lep/MC/mc_410000.ttbar_lep.2lep.root\"\n",
    "  norm1=0.0916632363839584 # ttbar normalisation\n",
    "  filename='ttlep_atlas.csv.gz'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-GwlBqK5ZtW"
   },
   "source": [
    "# Reading in the file\n",
    "\n",
    "The ATLAS ntuples are in root format. They also include a lot of information that we do not need for this exercise.\n",
    "\n",
    "Our aim is extracting the information we need, i.e. the 4-vectors of the two leptons and the missing transverse momentum from the ntuples, and to put it into a panda dataframe, which afterwards we can use to study how our events look like, and finally to develop a classification exercise.\n",
    "\n",
    "The three next boxes of code effect this data extraction, and have as an output the <i>dftot</i> dataframe\n",
    "\n",
    "You are welcome to understand the steps of the creation of the dataframe, this is very useful if you want to learn how to handle complex HEP ntuples.\n",
    "\n",
    "For the purposes of this course you can simply run them, assume you have a dataframe dftot, and you want to perform operations on it\n",
    "\n",
    "Steps:\n",
    "\n",
    "* Read in the tree with uproot https://pypi.org/project/uproot/, and check number of events and structure of tree\n",
    "* Define variables of the ntuple  which are of interest for our analysis, we have two groups\n",
    "  * The vectors of leptons\n",
    "  * The Missing ET and number of jets\n",
    "* Store them into a series of awkward arrays  https://awkward-array.org/doc/main/index.html\n",
    "* Reformat the arrays to numpy vectors\n",
    "* Stack them\n",
    "* Insert them into a Panda dataframe\n",
    "* Label the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "runNumber            | int32_t                  | AsDtype('>i4')\n",
      "eventNumber          | int32_t                  | AsDtype('>i4')\n",
      "channelNumber        | int32_t                  | AsDtype('>i4')\n",
      "mcWeight             | float                    | AsDtype('>f4')\n",
      "scaleFactor_PILEUP   | float                    | AsDtype('>f4')\n",
      "scaleFactor_ELE      | float                    | AsDtype('>f4')\n",
      "scaleFactor_MUON     | float                    | AsDtype('>f4')\n",
      "scaleFactor_PHOTON   | float                    | AsDtype('>f4')\n",
      "scaleFactor_TAU      | float                    | AsDtype('>f4')\n",
      "scaleFactor_BTAG     | float                    | AsDtype('>f4')\n",
      "scaleFactor_LepTR... | float                    | AsDtype('>f4')\n",
      "scaleFactor_Photo... | float                    | AsDtype('>f4')\n",
      "trigE                | bool                     | AsDtype('bool')\n",
      "trigM                | bool                     | AsDtype('bool')\n",
      "trigP                | bool                     | AsDtype('bool')\n",
      "lep_n                | uint32_t                 | AsDtype('>u4')\n",
      "lep_truthMatched     | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "lep_trigMatched      | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "lep_pt               | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "lep_eta              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "lep_phi              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "lep_E                | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "lep_z0               | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "lep_charge           | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "lep_type             | std::vector<uint32_t>    | AsJagged(AsDtype('>u4'), he...\n",
      "lep_isTightID        | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "lep_ptcone30         | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "lep_etcone20         | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "lep_trackd0pvunbi... | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "lep_tracksigd0pvu... | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "met_et               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "jet_n                | uint32_t                 | AsDtype('>u4')\n",
      "jet_pt               | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "jet_eta              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "jet_phi              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "jet_E                | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "jet_jvt              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "jet_trueflav         | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "jet_truthMatched     | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "jet_MV2c10           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "photon_n             | uint32_t                 | AsDtype('>u4')\n",
      "photon_truthMatched  | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "photon_trigMatched   | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "photon_pt            | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "photon_eta           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "photon_phi           | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "photon_E             | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "photon_isTightID     | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "photon_ptcone30      | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "photon_etcone20      | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "photon_convType      | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "tau_n                | uint32_t                 | AsDtype('>u4')\n",
      "tau_pt               | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "tau_eta              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "tau_phi              | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "tau_E                | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "tau_isTightID        | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "tau_truthMatched     | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "tau_trigMatched      | std::vector<bool>        | AsJagged(AsDtype('bool'), h...\n",
      "tau_nTracks          | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "tau_BDTid            | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "ditau_m              | float                    | AsDtype('>f4')\n",
      "lep_pt_syst          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "met_et_syst          | float                    | AsDtype('>f4')\n",
      "jet_pt_syst          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "photon_pt_syst       | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "tau_pt_syst          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "XSection             | float                    | AsDtype('>f4')\n",
      "SumWeights           | float                    | AsDtype('>f4')\n",
      "largeRjet_n          | uint32_t                 | AsDtype('>u4')\n",
      "largeRjet_pt         | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "largeRjet_eta        | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "largeRjet_phi        | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "largeRjet_E          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "largeRjet_m          | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "largeRjet_truthMa... | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "largeRjet_D2         | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "largeRjet_tau32      | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "largeRjet_pt_syst    | std::vector<float>       | AsJagged(AsDtype('>f4'), he...\n",
      "tau_charge           | std::vector<int32_t>     | AsJagged(AsDtype('>i4'), he...\n",
      "None\n",
      "Events in tree 2910539\n"
     ]
    }
   ],
   "source": [
    "numread=10000\n",
    "with uproot.open( fn1 + \":mini\") as tree1:    \n",
    "#\n",
    "#  Print out content of ntuple\n",
    "#\n",
    "    print(tree1.show())\n",
    "\n",
    "    numevents1 = tree1.num_entries # number of events\n",
    "    \n",
    "    print(\"Events in tree\",numevents1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charge in structure lep_momentum1 only the variables defined in vector tupvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meaning of the lepton variables:\n",
    "* lep_pt, lep_eta, lep_phi, lep_e:  components of 4-momenum of lepton in collider coordinates\n",
    "* lep_charge: chage of the lepton, +1 or -1\n",
    "* type of lepton:  electron=11   muon=13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables that we want to extract from the nuple:\n",
    "* The vectors with the characteristics of leptons in the event\n",
    "* The two components of the missing tranverse momentum: modulus and azimuthal anglr\n",
    "* The number of jets in the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lepvar=[\"lep_pt\", \"lep_eta\", \"lep_phi\",\"lep_E\",\n",
    "        \"lep_charge\",\"lep_type\"]\n",
    "scalvar=[\"met_et\",\"met_phi\",\"jet_n\"]\n",
    "\n",
    "weivar=[\"mcWeight\"] # variables to calculate Monte Carlo weight\n",
    "\n",
    "tupvar=lepvar+scalvar+weivar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lep_momentum1 = tree1.arrays(tupvar,entry_stop=numread,library=\"ak\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leptons in the event appear in the ntuple as vectors which have a size corresponding to the number of leptons in the event (variable lep_n). The events in the used data samples have at least two leptons.\n",
    "We want to store the components of the first and second leptons in dedicated vectors with variable names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnam=[\"ptl1\",\"etal1\",\"phil1\",\"el1\",\"chl1\",\"typl1\",\n",
    "        \"ptl2\",\"etal2\",\"phil2\",\"el2\",\"chl2\",\"typl2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numpy vector assuming that lep_ arrays have 2 components\n",
    "for i in range(0,2):\n",
    "   for j in range(0,len(lepvar)):\n",
    "     if i==0 and j==0:\n",
    "       ptlep1=ak.to_numpy(lep_momentum1[lepvar[j]][:,i])\n",
    "     else:\n",
    "       ptlep1=np.vstack([ptlep1,ak.to_numpy(lep_momentum1[lepvar[j]][:,i])])\n",
    "# end up with numpy 2d vector with n_var rows and n_event columns\n",
    "# to transpose, as in pandas 'features' are columns and 'observations' rows\n",
    "ptlep1=ptlep1.transpose()\n",
    "# create dataframe \n",
    "dftot = pd.DataFrame(ptlep1)\n",
    "# add names of columns\n",
    "dftot.columns=colnam# add normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add scalar variables\n",
    "for i in range(0, len(scalvar)):\n",
    "   dftot[scalvar[i]]=lep_momentum1[scalvar[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add normalisation\n",
    "dftot[\"totalWeight\"]=lep_momentum1[weivar[0]]*norm1*numevents1/numread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ptl1', 'etal1', 'phil1', 'el1', 'chl1', 'typl1', 'ptl2', 'etal2',\n",
      "       'phil2', 'el2', 'chl2', 'typl2', 'met_et', 'met_phi', 'jet_n',\n",
      "       'totalWeight'],\n",
      "      dtype='object')\n",
      "(10000, 16)\n",
      "           ptl1     etal1     phil1            el1  chl1  typl1          ptl2  \\\n",
      "0  68258.742188  0.573097  2.797778   79778.437500  -1.0   13.0  32021.345703   \n",
      "1  35269.156250 -1.321083 -1.891969   70790.914062   1.0   11.0  13273.810547   \n",
      "2  59904.750000 -1.798291 -2.042090  185851.484375   1.0   11.0  16296.021484   \n",
      "3  62116.527344 -0.077092  0.415694   62301.207031   1.0   11.0  30084.500000   \n",
      "4  52995.558594  0.484091 -0.398400   59327.367188   1.0   11.0  20755.710938   \n",
      "\n",
      "      etal2     phil2            el2  chl2  typl2         met_et   met_phi  \\\n",
      "0 -0.520212  1.882341   36452.757812   1.0   11.0   25995.283203 -0.886724   \n",
      "1 -1.938462 -0.744185   47068.914062  -1.0   13.0  127970.046875  2.881174   \n",
      "2 -2.553680  2.423617  105371.085938  -1.0   13.0   43242.371094 -0.558963   \n",
      "3  0.654615  3.088204   36763.921875  -1.0   11.0   51946.667969  1.474338   \n",
      "4 -0.104866 -2.001026   20870.207031  -1.0   13.0  179923.562500  0.553834   \n",
      "\n",
      "   jet_n  totalWeight  \n",
      "0      2     26.67894  \n",
      "1      3     26.67894  \n",
      "2      4     26.67894  \n",
      "3      1     26.67894  \n",
      "4      2     26.67894  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 16 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ptl1         10000 non-null  float64\n",
      " 1   etal1        10000 non-null  float64\n",
      " 2   phil1        10000 non-null  float64\n",
      " 3   el1          10000 non-null  float64\n",
      " 4   chl1         10000 non-null  float64\n",
      " 5   typl1        10000 non-null  float64\n",
      " 6   ptl2         10000 non-null  float64\n",
      " 7   etal2        10000 non-null  float64\n",
      " 8   phil2        10000 non-null  float64\n",
      " 9   el2          10000 non-null  float64\n",
      " 10  chl2         10000 non-null  float64\n",
      " 11  typl2        10000 non-null  float64\n",
      " 12  met_et       10000 non-null  float32\n",
      " 13  met_phi      10000 non-null  float32\n",
      " 14  jet_n        10000 non-null  uint32 \n",
      " 15  totalWeight  10000 non-null  float32\n",
      "dtypes: float32(3), float64(12), uint32(1)\n",
      "memory usage: 1.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# inspect dataframe\n",
    "coln=dftot.columns\n",
    "\n",
    "print(coln)\n",
    "\n",
    "print(dftot.shape)\n",
    "\n",
    "print(dftot.head())\n",
    "\n",
    "print(dftot.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write dataframe to csv\n",
    "dftot.to_csv(filename,compression={'method': 'gzip', 'compresslevel': 1, 'mtime': 1},index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAczWo8i5Ztd"
   },
   "source": [
    "<a id='going_further'></a>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
