{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiSTHbA25ZtB"
   },
   "source": [
    "# Testing basic ML algorithms in 2d \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of Logistic regression (LR) and of decision tree (DT) on a classification task with two variables, and a well defined separation line on the 2-d plane.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance verification :\n",
    "    \n",
    "* Look at evolution of loss as a function of the epoch for training and validation samples (only for LR)\n",
    "* Plot distribution of output probability for signal and background\n",
    "* Plot ROC\n",
    "* For relevant variables compare distribution for events with probability<0.5 and events with probability<0.5\n",
    "* Write out the optimised weights to nderstand the relative importance of variables (LR)\n",
    "* Draw the final tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate pattern in 2-d space\n",
    "\n",
    "Divide a 2-d space in two regions based on a function of the two variables, \n",
    "and populate the two regions with randomly distributed points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how many events you want\n",
    "n=10000\n",
    "# generate random inputs in [-0.5, 0.5]\n",
    "X1 = np.random.random(n)-0.5\n",
    "X2 = np.random.random(n)-0.5\n",
    "# Define partition of space as a boolean function of the two variables\n",
    "Y = X1*0.2+X2*0.3<0\n",
    "# Y=((X1<0) & (X2<0)) | ((X1>0.25) & (X2>0.25))\n",
    "#Y=((X1<-0.33) & (X2<0)) | ((X1>0.28) & (X2>0.40))\n",
    "#Y=X1*X1*0.3-X2*0.2>0\n",
    "#Y=X1*X1*0.3-X2*0.2>0\n",
    "# stacking requires vectors to be defined as 2-d vector with\n",
    "# second dimension=1\n",
    "X1 = X1.reshape(n, 1)\n",
    "X2 = X2.reshape(n, 1)\n",
    "Y = Y.reshape(n, 1)\n",
    "# print(X1)\n",
    "# print(X2)\n",
    "# print(Y)\n",
    "data= np.hstack((X1, X2, Y))\n",
    "# print(data)\n",
    "df = pd.DataFrame(data,columns=['x1', 'x2','SIG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise generated patterns in 2-d parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scat(df, sel1, sel2, var1, var2, blx, bhx, bly, bhy):\n",
    "  df_pass = df.query(sel1)\n",
    "  df_nopass = df.query(sel2)\n",
    "  fig= plt.figure(figsize=(14,5))\n",
    "  plt.subplot(1, 2,1)\n",
    "  plt.xlim([blx,bhx])\n",
    "  plt.ylim([bly,bhy])\n",
    "  plt.plot(df_nopass[var1], df_nopass[var2], 'bo', alpha=0.4, label=sel2)\n",
    "  plt.legend(loc='best')\n",
    "  plt.xlabel(var1)\n",
    "  plt.ylabel(var2)\n",
    "  plt.subplot(1, 2,2)\n",
    "  plt.xlim([blx,bhx])\n",
    "  plt.ylim([blx,bhx])\n",
    "  plt.plot(df_pass[var1], df_pass[var2], 'ro', alpha=0.4, label=sel1)\n",
    "  plt.legend(loc='best')\n",
    "  plt.xlabel(var1)\n",
    "  plt.ylabel(var2)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the covered area for the two \n",
    "\n",
    "sel1='SIG==0'\n",
    "sel2='SIG==1'\n",
    "plot_scat(df, sel1, sel2, 'x1', 'x2', -0.5, 0.5, -0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train test and validation with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Define vectors for input to ML\n",
    "# Use 'SIG' column as definition of target\n",
    "y = df['SIG']\n",
    "# define dataframe out of all columns except the \"SIG\" one\n",
    "X = df[[col for col in df.columns if col!=\"SIG\"]]\n",
    "col_fin=X.columns\n",
    "X_tv, X_test, y_tv, y_test = train_test_split(X, y,\n",
    "                                   test_size=.25, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv,\n",
    "                                   test_size=.10, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "Implement in Keras and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "from tensorflow import keras\n",
    "#from keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "\n",
    "varnum=X_train.shape[1]\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(1, input_dim=varnum, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history=model.fit(X_train, y_train, \n",
    "                  validation_data=(X_val,y_val), \n",
    "                  batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypredr=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe with labels and probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_acc_r=X_test.copy()\n",
    "df_test_acc_r['SIG']=y_test\n",
    "df_test_acc_r['PROB']=Ypredr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at the classification performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot history of losses along epochs for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('regression')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of output probabilities  for signal and backround\n",
    "\n",
    "The output of the classification is for each event a number between 0 and 1 representing the probability that that event is a signal event. Since for each event we know whether it was a signal (SIG=1) or a background (SIG=0), we can plot the output probability of the network for each of the two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split according to the label\n",
    "df_test_acc_r_bkg = df_test_acc_r.query('SIG==0')\n",
    "df_test_acc_r_sig = df_test_acc_r.query('SIG==1')\n",
    "print('nsig ',df_test_acc_r_sig.shape[0])\n",
    "print('nbkg ',df_test_acc_r_bkg.shape[0])\n",
    "bins = np.linspace(0, 1,50)\n",
    "plt.hist(df_test_acc_r_bkg.PROB, bins, alpha=0.5, density=True, label='Background')\n",
    "plt.hist(df_test_acc_r_sig.PROB, bins, alpha=0.5, density=True, label='Signal')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC curve and calculate AUC\n",
    "In order to perform our the final selection we put a lower limit on the value of the probability and we count the fraction of events above this limit for both signal and backround, i.e for each value of PROB we have two values: The 'true positive rate (TPR)' (efficiency of signal selection in HEP language), and 'false positive rate (FPR)' (efficency for selecting background). If we TPR versus FPR the other as a function of PROB we obtain a curve called the Receive Operating Characteristic (ROC) curve https://en.wikipedia.org/wiki/Receiver_operating_characteristic. Methods for building the ROC curve are availabel in sklearn.metrics. An ideal ROC curve would be along upper x and left y axes of the plot, corresponding to the case where all of the signal events have PROB=1 and all background events have PROB=0. The worst case is a curve where TPR=FPR, i.e. the discrimination power is the same as extracting a random number for PROB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.plot([0.001, 1], [0, 1], 'k--')\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, Ypredr)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(\"Regression auc \",auc_keras)\n",
    "plt.plot(fpr_keras, tpr_keras, label='Regresssion AUC = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise patterns in 2-d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1='SIG==0'\n",
    "sel2='SIG==1'\n",
    "print(sel1,sel2)\n",
    "plot_scat(df_test_acc_r, sel1, sel2, 'x1', 'x2', -0.5, 0.5, -0.5, 0.5)\n",
    "thrmax=0.5\n",
    "sel1='PROB<'+str(thrmax)\n",
    "sel2='PROB>'+str(thrmax)\n",
    "print(sel1,sel2)\n",
    "plot_scat(df_test_acc_r, sel1, sel2, 'x1', 'x2', -0.5, 0.5, -0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare label and prediction in 1-d projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_false='PROB<0.5'\n",
    "pred_true='PROB>0.5'\n",
    "lab_false='SIG==0'\n",
    "lab_true='SIG==1'\n",
    "nbin=50\n",
    "blow=-0.5\n",
    "bhigh=0.5\n",
    "bins = np.linspace(blow, bhigh, nbin)\n",
    "fig1= plt.figure(figsize=(14,5))\n",
    "plt.subplot(1, 2,1)\n",
    "var=\"x1\"\n",
    "plt.hist(df_test_acc_r.query(pred_false)[var], bins, alpha=0.5, density=True, label=pred_false)\n",
    "plt.hist(df_test_acc_r.query(pred_true)[var], bins, alpha=0.5, density=True, label=pred_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.subplot(1, 2,2)\n",
    "plt.hist(df_test_acc_r.query(lab_false)[var], bins, alpha=0.5, density=True, label=lab_false)\n",
    "plt.hist(df_test_acc_r.query(lab_true)[var], bins, alpha=0.5, density=True, label=lab_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.show()\n",
    "fig2= plt.figure(figsize=(14,5))\n",
    "plt.subplot(1, 2,1)\n",
    "var=\"x2\"\n",
    "plt.hist(df_test_acc_r.query(pred_false)[var], bins, alpha=0.5, density=True, label=pred_false)\n",
    "plt.hist(df_test_acc_r.query(pred_true)[var], bins, alpha=0.5, density=True, label=pred_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.subplot(1, 2,2)\n",
    "plt.hist(df_test_acc_r.query(lab_false)[var], bins, alpha=0.5, density=True, label=lab_false)\n",
    "plt.hist(df_test_acc_r.query(lab_true)[var], bins, alpha=0.5, density=True, label=lab_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_weights = model.layers[0].get_weights()[0]\n",
    "layer_biases  = model.layers[0].get_weights()[1]\n",
    "print('layer weights',layer_weights)\n",
    "print('layer biases',layer_biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifier\n",
    "\n",
    "Documentation for the possible options is in <br />\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "test_tree = pd.DataFrame(X_test)\n",
    "test_tree.columns=col_fin\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier(max_leaf_nodes=6, criterion='gini', splitter='best', random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "Ypredt=clf.predict_proba(test_tree)\n",
    "\n",
    "print('Training finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ypredt.shape)\n",
    "df_test_acc_t=X_test.copy()\n",
    "df_test_acc_t['SIG']=y_test\n",
    "df_test_acc_t['PROB']=Ypredt[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of output probabilities  for signal and backround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split according to the label\n",
    "df_test_acc_t_bkg = df_test_acc_t.query('SIG==0')\n",
    "df_test_acc_t_sig = df_test_acc_t.query('SIG==1')\n",
    "print('nsig ',df_test_acc_t_sig.shape[0])\n",
    "print('nbkg ',df_test_acc_t_bkg.shape[0])\n",
    "bins = np.linspace(0, 1,50)\n",
    "plt.hist(df_test_acc_t_bkg.PROB, bins, alpha=0.5, density=True, label='Background')\n",
    "plt.hist(df_test_acc_t_sig.PROB, bins, alpha=0.5, density=True, label='Signal')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC curve and calculate AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.plot([0.001, 1], [0, 1], 'k--')\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, Ypredt[:,1])\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(\"Regression auc \",auc_keras)\n",
    "plt.plot(fpr_keras, tpr_keras, label='Regresssion AUC = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise patterns in 2-d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1='SIG==0'\n",
    "sel2='SIG==1'\n",
    "print(sel1,sel2)\n",
    "plot_scat(df_test_acc_t, sel1, sel2, 'x1', 'x2', -0.5, 0.5, -0.5, 0.5)\n",
    "thrmax=0.5\n",
    "sel1='PROB<'+str(thrmax)\n",
    "sel2='PROB>'+str(thrmax)\n",
    "print(sel1,sel2)\n",
    "plot_scat(df_test_acc_t, sel1, sel2, 'x1', 'x2', -0.5, 0.5, -0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare label and prediction in 1-d projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_false='PROB<0.5'\n",
    "pred_true='PROB>0.5'\n",
    "lab_false='SIG==0'\n",
    "lab_true='SIG==1'\n",
    "nbin=50\n",
    "blow=-0.5\n",
    "bhigh=0.5\n",
    "bins = np.linspace(blow, bhigh, nbin)\n",
    "fig1= plt.figure(figsize=(14,5))\n",
    "plt.subplot(1, 2,1)\n",
    "var=\"x1\"\n",
    "plt.hist(df_test_acc_t.query(pred_false)[var], bins, alpha=0.5, density=True, label=pred_false)\n",
    "plt.hist(df_test_acc_t.query(pred_true)[var], bins, alpha=0.5, density=True, label=pred_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.subplot(1, 2,2)\n",
    "plt.hist(df_test_acc_t.query(lab_false)[var], bins, alpha=0.5, density=True, label=lab_false)\n",
    "plt.hist(df_test_acc_t.query(lab_true)[var], bins, alpha=0.5, density=True, label=lab_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.show()\n",
    "fig2= plt.figure(figsize=(14,5))\n",
    "plt.subplot(1, 2,1)\n",
    "var=\"x2\"\n",
    "plt.hist(df_test_acc_t.query(pred_false)[var], bins, alpha=0.5, density=True, label=pred_false)\n",
    "plt.hist(df_test_acc_t.query(pred_true)[var], bins, alpha=0.5, density=True, label=pred_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.subplot(1, 2,2)\n",
    "plt.hist(df_test_acc_t.query(lab_false)[var], bins, alpha=0.5, density=True, label=lab_false)\n",
    "plt.hist(df_test_acc_t.query(lab_true)[var], bins, alpha=0.5, density=True, label=lab_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                     class_names=[\"bad\",\"good\"],\n",
    "                     filled=True, rounded=True,\n",
    "                     special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uncomment and try different patterns in generation and look how the algorithms performs in different cases\n",
    "* Study dependence of performance from number of events\n",
    "* Study dependence of performance of regression from choice of optimizer number of epoch, size of batches\n",
    "* Study dependence of performance of decision tree from number of leaves/loss criterion\n",
    "* Extend generation to three variables, and test the algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Simple man  implementation of search for first splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Gini factor\n",
    "# 3 inputs: the total number of events, the number of events in each class (good,bad)\n",
    "def calc_gini(tot, good, bad):\n",
    "  eg = np.divide(good, tot, out=np.zeros_like(good), where=tot!=0)\n",
    "  eb = np.divide(bad, tot, out=np.zeros_like(bad), where=tot!=0)\n",
    "  gini=1-(eg)**2-(eb)**2\n",
    "  return gini\n",
    "#\n",
    "# Algorithm for splitting\n",
    "#\n",
    "def get_first_split(X,y,var):\n",
    "  X_split=X.copy()\n",
    "  X_split[\"cc\"]=y\n",
    "# x1 and x2 are between -0.5 and 0.5 scan them in step of 0.01\n",
    "  nbin=100\n",
    "  xbin = np.linspace(-0.5, 0.5, nbin)\n",
    "# create numpy arrays for scan\n",
    "  tot_p1= np.zeros(nbin)\n",
    "  good_p1= np.zeros(nbin)\n",
    "  bad_p1= np.zeros(nbin)\n",
    "  tot_p2= np.zeros(nbin)\n",
    "  good_p2= np.zeros(nbin)\n",
    "  bad_p2= np.zeros(nbin)\n",
    "  gini_p1=np.zeros(nbin)\n",
    "  gini_p2=np.zeros(nbin)\n",
    "#\n",
    "# loop on values of variable\n",
    "#\n",
    "  for i in range(0,len(xbin)):\n",
    "#  builds the strings for splitting\n",
    "    sel1=var+'<'+str(xbin[i])\n",
    "    sel1g=sel1+' & cc==0'\n",
    "    sel1b=sel1+' & cc==1'\n",
    "    sel2=var+'>'+str(xbin[i])\n",
    "    sel2g=sel2+' & cc==0'\n",
    "    sel2b=sel2+' & cc==1'\n",
    "# for each value calculate the number of good events (cc=0) and of bad events(cc=1)\n",
    "    tot_p1[i]=(X_split.query(sel1)).shape[0]\n",
    "    good_p1[i]=(X_split.query(sel1g)).shape[0]\n",
    "    bad_p1[i]=(X_split.query(sel1b)).shape[0]\n",
    "    tot_p2[i]=(X_split.query(sel2)).shape[0]\n",
    "    good_p2[i]=(X_split.query(sel2g)).shape[0]\n",
    "    bad_p2[i]=(X_split.query(sel2b)).shape[0]\n",
    "# calculate the gini for all points on each side of the split\n",
    "  gini_p1=calc_gini(tot_p1,good_p1,bad_p1)\n",
    "  gini_p2=calc_gini(tot_p2,good_p2,bad_p2)\n",
    "# plot Gini for each side of split\n",
    "  plt.plot(xbin,gini_p1,label=var+'<threshold')\n",
    "  plt.xlabel(var + ' threshold')\n",
    "  plt.ylabel('Gini value')\n",
    "  plt.show()\n",
    "  plt.plot(xbin,gini_p2)\n",
    "  plt.xlabel(var + ' threshold')\n",
    "  plt.ylabel('Gini value')\n",
    "  plt.show()\n",
    "# find minimum value of gini for each side\n",
    "  mgini_p1=np.amin(gini_p1)\n",
    "  mgini_p2=np.amin(gini_p2)\n",
    "# find for xhich value of the variable it happens on each side\n",
    "  cgini_p1=xbin[np.argmin(gini_p1)]\n",
    "  cgini_p2=xbin[np.argmin(gini_p2)]\n",
    "  cgini_out=cgini_p1\n",
    "  mgini_p1_out=mgini_p1\n",
    "# now choose the side\n",
    "  mgini_p2_out=gini_p2[np.argmin(gini_p1)]\n",
    "  isid=1\n",
    "  if mgini_p2<mgini_p1:\n",
    "    cgini_out=cgini_p2\n",
    "    mgini_p1_out=mgini_p2\n",
    "    mgini_p2_out=gini_p1[np.argmin(gini_p2)]\n",
    "    isid=2\n",
    "  return cgini_out,mgini_p1_out,mgini_p2_out,isid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "print(\"First split\")\n",
    "cx1,  gp1x1, gp2x1, isidx1= get_first_split(X_train,y_train,'x1')\n",
    "cx2,  gp1x2, gp2x2, isidx2= get_first_split(X_train,y_train,'x2')\n",
    "mgm=['<','>']\n",
    "mgs=mgm[0]\n",
    "if isidx1==2:\n",
    "  mgs=mgm[1]\n",
    "gminx1=min(gp1x1,gp2x1)\n",
    "gminx2=min(gp1x2,gp2x1)\n",
    "cutstrl=\"x1\"+mgs+str(cx1)\n",
    "cutstrr=\"x1\"+mgs+str(cx1)\n",
    "if gminx2 < gminx1:\n",
    "  mgs=mgm[0]\n",
    "  if isidx2==2:\n",
    "    mgs=mgm[1]\n",
    "  cutstrl=\"x2\"+mgs+str(cx2)\n",
    "  cutstrr=\"x2>\"+mgs+str(cx2)\n",
    "print('cut x1',cx1,' gini left',gp1x1,'gini right', gp2x1, 'side',isidx1)\n",
    "print('cut x2',cx2,' gini left',gp1x2,'gini right', gp2x2, 'side',isidx2)\n",
    "print(\"splitting condition is\",cutstrl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
