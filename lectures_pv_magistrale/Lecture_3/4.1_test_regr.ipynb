{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TiSTHbA25ZtB"
   },
   "source": [
    "# Testing basic ML algorithms in 2d \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of Logistic regression (LR) and of decision tree (DT) on a classification task with two variables, and a well defined separation line on the 2-d plane.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance verification :\n",
    "    \n",
    "* Look at evolution of loss as a function of the epoch for training and validation samples (only for LR)\n",
    "* Plot distribution of output probability for signal and background\n",
    "* Plot ROC\n",
    "* For relevant variables compare distribution for events with probability<0.5 and events with probability<0.5\n",
    "* Write out the optimised weights to nderstand the relative importance of variables (LR)\n",
    "* Draw the final tree (DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math # for mathematical functions such as square root\n",
    "import numpy as np # for numerical calculations such as histogramming\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate pattern in 2-d space\n",
    "\n",
    "Divide a 2-d space in two regions based on a function of the two variables, \n",
    "and populate the two regions with randomly distributed points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how many events you want\n",
    "n=10000\n",
    "# generate random inputs in [-0.5, 0.5]\n",
    "X1 = np.random.random(n)-0.5\n",
    "X2 = np.random.random(n)-0.5\n",
    "# Define partition of space as a boolean function of the two variables\n",
    "# Y = X1*0.2+X2*0.3<0\n",
    "# Y=((X1<0) & (X2<0)) | ((X1>0.25) & (X2>0.25))\n",
    "#Y=((X1<-0.33) & (X2<0)) | ((X1>0.28) & (X2>0.40))\n",
    "#Y=X1*X1*0.3-X2*0.2>0\n",
    "Y=X1*X1*0.3-X2*0.2>0\n",
    "# stacking requires vectors to be defined as 2-d vector with\n",
    "# second dimension=1\n",
    "X1 = X1.reshape(n, 1)\n",
    "X2 = X2.reshape(n, 1)\n",
    "Y = Y.reshape(n, 1)\n",
    "# print(X1)\n",
    "# print(X2)\n",
    "# print(Y)\n",
    "data= np.hstack((X1, X2, Y))\n",
    "# print(data)\n",
    "df = pd.DataFrame(data,columns=['x1', 'x2','SIG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise generated patterns in 2-d parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scat(df, sel1, sel2, var1, var2, blx, bhx, bly, bhy):\n",
    "  df_pass = df.query(sel1)\n",
    "  df_nopass = df.query(sel2)\n",
    "  fig= plt.figure(figsize=(14,5))\n",
    "  plt.subplot(1, 2,1)\n",
    "  plt.xlim([blx,bhx])\n",
    "  plt.ylim([bly,bhy])\n",
    "  plt.plot(df_nopass[var1], df_nopass[var2], 'bo', alpha=0.4, label=sel2)\n",
    "  plt.legend(loc='best')\n",
    "  plt.xlabel(var1)\n",
    "  plt.ylabel(var2)\n",
    "  plt.subplot(1, 2,2)\n",
    "  plt.xlim([blx,bhx])\n",
    "  plt.ylim([blx,bhx])\n",
    "  plt.plot(df_pass[var1], df_pass[var2], 'ro', alpha=0.4, label=sel1)\n",
    "  plt.legend(loc='best')\n",
    "  plt.xlabel(var1)\n",
    "  plt.ylabel(var2)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the covered area for the two \n",
    "\n",
    "sel1='SIG==0'\n",
    "sel2='SIG==1'\n",
    "plot_scat(df, sel1, sel2, 'x1', 'x2', -0.5, 0.5, -0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train test and validation with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Define vectors for input to ML\n",
    "# Use 'SIG' column as definition of target\n",
    "y = df['SIG']\n",
    "# define dataframe out of all columns except the \"SIG\" one\n",
    "X = df[[col for col in df.columns if col!=\"SIG\"]]\n",
    "col_fin=X.columns\n",
    "X_tv, X_test, y_tv, y_test = train_test_split(X, y,\n",
    "                                   test_size=.25, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv,\n",
    "                                   test_size=.10, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree classifier family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set which one to run \n",
    "#  1: decision tree\n",
    "#  2: random forest\n",
    "#  3: adaboost \n",
    "#  4: gradient boost\n",
    "#  5: XGB\n",
    "runtree=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree = pd.DataFrame(X_test)\n",
    "test_tree.columns=col_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple decision tree\n",
    "\n",
    "Documentation for the possible options is in <br />\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runtree==1:\n",
    "  from sklearn.tree import DecisionTreeClassifier\n",
    "  from sklearn import tree\n",
    "\n",
    "  clf = DecisionTreeClassifier(max_leaf_nodes=6, criterion='gini', splitter='best', random_state=0)\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  Ypredt=clf.predict_proba(test_tree)\n",
    "\n",
    "  print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runtree==2:\n",
    "  from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "  clf = RandomForestClassifier(max_depth=5, max_features=\"sqrt\", max_leaf_nodes=6, n_estimators=100, random_state=0)\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  Ypredt=clf.predict_proba(test_tree)\n",
    " \n",
    "  print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runtree==3:\n",
    "  from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "  clf = AdaBoostClassifier(n_estimators=100, learning_rate=1, random_state=0)\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  Ypredt=clf.predict_proba(test_tree)\n",
    " \n",
    "  print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boost classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runtree==4:\n",
    "  from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "  clf = GradientBoostingClassifier(max_depth=3, n_estimators=100, random_state=0)\n",
    "  clf.fit(X_train, y_train)\n",
    "\n",
    "  Ypredt=clf.predict_proba(test_tree)\n",
    " \n",
    "  print('Training finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB\n",
    "\n",
    "https://xgboost.readthedocs.io/en/stable/python/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runtree==5:\n",
    "  import xgboost as xgb  \n",
    "  import time\n",
    "  print(xgb.__version__)\n",
    "\n",
    "#Use default parameters and train on full dataset\n",
    "  XGBclassifier = xgb.sklearn.XGBClassifier(nthread=7, seed=1, objective='binary:logistic', use_label_encoder=False,\n",
    "                                          eta=0.05, max_depth=3, n_estimators=100)\n",
    "#Train and time classifier\n",
    "  start_time = time.time()\n",
    "  eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "  XGBclassifier.fit(X_train, y_train, eval_metric=[\"logloss\"], eval_set=eval_set,verbose=True  )\n",
    "  run_time = time.time() - start_time\n",
    "\n",
    "#XGBclassifier.save_model('xgb_test')\n",
    "  Ypredt= XGBclassifier.predict_proba(X_test)[:,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runtree==5:\n",
    "  results = XGBclassifier.evals_result()\n",
    "  epochs = len(results['validation_0']['logloss'])\n",
    "  x_axis = range(0, epochs)\n",
    "    \n",
    "# plot log loss\n",
    "  fig, ax = plt.subplots(figsize=(10,10))\n",
    "  ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "  ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "  ax.legend()\n",
    "    \n",
    "  plt.ylabel('Log Loss')\n",
    "  plt.title('XGBoost Log Loss')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ypredt.shape)\n",
    "df_test_acc_t=X_test.copy()\n",
    "df_test_acc_t['SIG']=y_test\n",
    "if runtree<5:\n",
    "  df_test_acc_t['PROB']=Ypredt[:,1]\n",
    "if runtree==5:\n",
    "  df_test_acc_t['PROB']=Ypredt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot distribution of output probabilities  for signal and backround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split according to the label\n",
    "df_test_acc_t_bkg = df_test_acc_t.query('SIG==0')\n",
    "df_test_acc_t_sig = df_test_acc_t.query('SIG==1')\n",
    "print('nsig ',df_test_acc_t_sig.shape[0])\n",
    "print('nbkg ',df_test_acc_t_bkg.shape[0])\n",
    "bins = np.linspace(0, 1,50)\n",
    "plt.hist(df_test_acc_t_bkg.PROB, bins, alpha=0.5, density=True, label='Background')\n",
    "plt.hist(df_test_acc_t_sig.PROB, bins, alpha=0.5, density=True, label='Signal')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC curve and calculate AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "plt.plot([0.001, 1], [0, 1], 'k--')\n",
    "if runtree<5:\n",
    "  fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, Ypredt[:,1])\n",
    "if runtree==5:\n",
    "  fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, Ypredt)\n",
    "\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(\"Regression auc \",auc_keras)\n",
    "plt.plot(fpr_keras, tpr_keras, label='Tree AUC = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.show    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise patterns in 2-d space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel1='SIG==0'\n",
    "sel2='SIG==1'\n",
    "print(sel1,sel2)\n",
    "plot_scat(df_test_acc_t, sel1, sel2, 'x1', 'x2', -0.5, 0.5, -0.5, 0.5)\n",
    "thrmax=0.5\n",
    "sel1='PROB<'+str(thrmax)\n",
    "sel2='PROB>'+str(thrmax)\n",
    "print(sel1,sel2)\n",
    "plot_scat(df_test_acc_t, sel1, sel2, 'x1', 'x2', -0.5, 0.5, -0.5, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare label and prediction in 1-d projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_false='PROB<0.5'\n",
    "pred_true='PROB>0.5'\n",
    "lab_false='SIG==0'\n",
    "lab_true='SIG==1'\n",
    "nbin=50\n",
    "blow=-0.5\n",
    "bhigh=0.5\n",
    "bins = np.linspace(blow, bhigh, nbin)\n",
    "fig1= plt.figure(figsize=(14,5))\n",
    "plt.subplot(1, 2,1)\n",
    "var=\"x1\"\n",
    "plt.hist(df_test_acc_t.query(pred_false)[var], bins, alpha=0.5, density=True, label=pred_false)\n",
    "plt.hist(df_test_acc_t.query(pred_true)[var], bins, alpha=0.5, density=True, label=pred_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.subplot(1, 2,2)\n",
    "plt.hist(df_test_acc_t.query(lab_false)[var], bins, alpha=0.5, density=True, label=lab_false)\n",
    "plt.hist(df_test_acc_t.query(lab_true)[var], bins, alpha=0.5, density=True, label=lab_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.show()\n",
    "fig2= plt.figure(figsize=(14,5))\n",
    "plt.subplot(1, 2,1)\n",
    "var=\"x2\"\n",
    "plt.hist(df_test_acc_t.query(pred_false)[var], bins, alpha=0.5, density=True, label=pred_false)\n",
    "plt.hist(df_test_acc_t.query(pred_true)[var], bins, alpha=0.5, density=True, label=pred_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.subplot(1, 2,2)\n",
    "plt.hist(df_test_acc_t.query(lab_false)[var], bins, alpha=0.5, density=True, label=lab_false)\n",
    "plt.hist(df_test_acc_t.query(lab_true)[var], bins, alpha=0.5, density=True, label=lab_true)\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(var)\n",
    "plt.ylabel('normalised events')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize tree (only for simpe tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if runtree==1:\n",
    "  import graphviz\n",
    "  dot_data = tree.export_graphviz(clf, out_file=None)\n",
    "  dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                     class_names=[\"bad\",\"good\"],\n",
    "                     filled=True, rounded=True,\n",
    "                     special_characters=True)\n",
    "  graph = graphviz.Source(dot_data)\n",
    "  graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Uncomment and try different patterns in generation and look how the algorithms performs in different cases\n",
    "* Study dependence of performance from number of events\n",
    "* Study dependence of performance of regression from choice of optimizer number of epoch, size of batches\n",
    "* Study dependence of performance of decision tree from number of leaves, depth of tree\n",
    "* For ensemble methods study performance as a function of number of estimators\n",
    "* Extend generation to three variables, and test the algorithms"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
